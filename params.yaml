XG_Boost:
    n_estimators: [200, 250, 300, 350,400, 450, 500]
    max_depth: [3,5,10,15, 20, 25,30]
    learning_rate: [0.01, 0.1, 0.3, 0.02, 0.2, 1, 0.03]
    subsample: [0.1, 0.5, 0.7, 0.3, 0.2,0.4,0.6]
#    eta: [ 0.3, 0.1, 0.01]
    colsample_bytree:  [0.1, 0.5, 0.7, 0.3, 0.2,0.4,0.6]
    'reg_alpha': [0.01, 0.1, 0.3, 0.02, 0.2, 1, 0.03]

#base_score=0.5, booster='gbtree',
                #                               n_estimators=200,
                #                               # early_stopping_rounds=50,
                #                               objective='reg:squarederror',
                #                               max_depth=6,
                #                               learning_rate=0.01,
                #                                min_child_weight=1,
                #                               subsample=0.8,
                #                               colsample_bytree=0.8,
                #                               gamma=0,
                #                               reg_alpha=0,
                #                               reg_lambda=1